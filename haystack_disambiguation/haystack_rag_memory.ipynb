{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.utils import Secret\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0734c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_data_hava_dups = []\n",
    "# with open(\"input_52_ch_en.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        train_data_hava_dups.append(line.strip())\n",
    "# remove duplicates in train_data\n",
    "train_data_hava_dups = list(set(train_data_hava_dups))\n",
    "for line in train_data_hava_dups:\n",
    "    train_data.append(Document(content=line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9450ea57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents(\n",
    "    train_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8962b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read api_key.txt to get the API key\n",
    "with open(\"api_key.txt\", \"r\") as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecda1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000001551B1265F0>\n",
       "ğŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_template = \"\"\"\n",
    "According to the contents of this website:\n",
    "{% for document in documents %}\n",
    "  {{document.content}}\n",
    "{% endfor %}\n",
    "Answer the given question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "llm = OpenAIGenerator(\n",
    "    api_key=Secret.from_env_var(\"GROQ_API_KEY\"),\n",
    "    api_base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama3-70b-8192\",\n",
    "    generation_kwargs = {\"max_tokens\": 1024}\n",
    ")\n",
    "pipeline = Pipeline()\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d1fac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ“šç¶²ç«™çš„å…§å®¹ï¼Œæ»‡é»”åœŸå¸ã›°ç¦®è¨˜çš„ä½œè€…é™³é¼å’Œæ»‡é»”ç´€éŠçš„ä½œè€…æ˜¯åŒä¸€ä¸ªäººã€‚\n",
      "\n",
      "ç†ç”±å¦‚ä¸‹ï¼š\n",
      "\n",
      "1. é™³é¼æ˜¯æ»‡é»”åœŸå¸ã›°ç¦®è¨˜çš„ä½œè€…ï¼Œé€™å¯ä»¥åœ¨è©²æ›¸çš„ä½œè€…æ¬„ä¸­æ‰¾åˆ°ã€‚\n",
      "2. æ»‡é»”ç´€éŠçš„ä½œè€…ä¹Ÿæ˜¯ä¸€ä½åå«é™³é¼çš„äººï¼Œé€™å¯ä»¥åœ¨è©²æ›¸çš„ä½œè€…æ¬„ä¸­æ‰¾åˆ°ã€‚\n",
      "3. å°æ¯”å…©æœ¬æ›¸çš„ä½œè€…ç”Ÿå¹³ï¼Œç™¼ç¾å…©äººçš„birthdayã€ç±è²«ã€è‘—è¿°ç­‰è³‡è¨Šå®Œå…¨ç›¸åŒã€‚\n",
      "4. ç”±æ–¼å…©äººçš„ç”Ÿå¹³è³‡æ–™å®Œå…¨ç›¸åŒï¼Œå› æ­¤å¯ä»¥æ–·å®šæ»‡é»”åœŸå¸ã›°ç¦®è¨˜çš„ä½œè€…é™³é¼å’Œæ»‡é»”ç´€éŠçš„ä½œè€…æ˜¯åŒä¸€å€‹äººã€‚\n",
      "\n",
      "å› æ­¤ï¼Œæ ¹æ“šä»¥ä¸Šç†ç”±ï¼Œæˆ‘å€‘å¯ä»¥æ–·å®šæ»‡é»”åœŸå¸ã›°ç¦®è¨˜çš„ä½œè€…é™³é¼å’Œæ»‡é»”ç´€éŠçš„ä½œè€…æ˜¯åŒä¸€å€‹äººã€‚\n"
     ]
    }
   ],
   "source": [
    "# question = \"Based on the documents, are the author named é™³é¼ of æ»‡é»”åœŸå¸ã›°ç¦®è¨˜ and the author of æ»‡é»”ç´€æ¸¸ the same person? Please provide your reasons.\"\n",
    "question = \"ç”¨ä¸­æ–‡å›ç­”ã€‚æ ¹æ“šé€™äº›æ–‡ä»¶ï¼Œç‰¹åˆ¥æ˜¯ä»–å€‘ç”Ÿå¹³ï¼Œè­¬å¦‚ courtesy name, style nameã€è‘—è¿°ï¼Œå“ªè£¡äººçš„è³‡è¨Šå‘Šè¨´æˆ‘ï¼Œæ»‡é»”åœŸå¸ã›°ç¦®è¨˜çš„ä½œè€…é™³é¼å’Œæ»‡é»”ç´€éŠçš„ä½œè€…æ˜¯åŒä¸€å€‹äººå—ï¼Ÿè«‹æä¾›ä½ çš„ç†ç”±ã€‚\"\n",
    "results = rag_pipeline.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
