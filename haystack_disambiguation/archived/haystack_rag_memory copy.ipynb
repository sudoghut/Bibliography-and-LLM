{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sudos\\anaconda3\\envs\\haystack\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.utils import Secret\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0734c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_data_hava_dups = []\n",
    "# with open(\"input_52_ch_en.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        train_data_hava_dups.append(line.strip())\n",
    "# remove duplicates in train_data\n",
    "train_data_hava_dups = list(set(train_data_hava_dups))\n",
    "for line in train_data_hava_dups:\n",
    "    train_data.append(Document(content=line))\n",
    "\n",
    "# train_data= [\n",
    "#         Document(content=\"The meaning of ä¸€æ´—ä¸‡å¤ is thatã€æ¸…ã€‘è©¹äº‹åºœå¸ç»å±€æ´—é©¬ä¹‹è°‘ç§°ï¼Œæ„æŒ‡å®˜è‡³æ­¤ï¼Œå…¶åä¹‹å‡é˜¶æ— æœ›ã€‚æ¸…ä½•åˆšå¾·ã€Šè¯æ¢¦é›†ã€‹å·ä¸Šï¼šâ€œä¸‰é“¨é€‰æ ¼å¤±è°ƒåœï¼Œé²‡ç«¹åŠŸå…æ»å…¸ç»ã€‚â€è‡ªæ³¨ï¼šâ€œâ€˜ä¸€æ´—ä¸‡å¤â€™ï¼Œäº¬æ›¹è°‘è¯­ä¹Ÿã€‚ç¿°æ—è½¬åˆ°è©¹äº‹åºœå¸ç»å±€æ´—é©¬ï¼Œå‡é˜¶ä¾¿æ»ã€‚äººå› â€˜ä¸€æ´—ä¸‡å¤å‡¡é©¬ç©ºâ€™ä¹‹å¥ï¼Œå˜²ä¹‹æ›°â€˜ä¸€æ´—ä¸‡å¤â€™ï¼Œäº¦ä»¥æ¸…æœä¸ç«‹ä¸œå®«ï¼Œæ•…å®˜åˆ¶ä¸ç”šä»‹æ„ä¹Ÿã€‚â€\"),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9450ea57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents(\n",
    "    train_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1a4caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x00000240F9DC9DE0>\n",
       "ğŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OllamaGenerator\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\n",
    "Documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "llm = OllamaGenerator(\n",
    "    model=\"phi3:medium\",\n",
    "    url=\"http://localhost:11434/api/generate\",\n",
    "    generation_kwargs={\n",
    "        \"num_predict\": 1000,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e675a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' æ ¹æ®æ–‡æ¡£ï¼Œèº«è¨€ä¹¦åˆ¤æ˜¯æŒ‡å”æœé€‰å®˜æ—¶çš„è€ƒæ ¸å†…å®¹ã€‚å³é€šè¿‡ç¤¼éƒ¨è¯•åï¼Œè¿›å£«åŠç¬¬è€…ä¸èƒ½ç›´æ¥è·å¾—å®˜ä½ï¼Œè¿˜éœ€è¦å†é€šè¿‡åéƒ¨é€‰å®˜ä¸€é˜¶æ®µã€‚è¿™ä¸ªé˜¶æ®µåŒ…æ‹¬ä¹¦åˆ¤ã€èº«è¨€ä¸¤é¡¹è€ƒæŸ¥ã€‚ä¹¦åˆ¤æ˜¯æŒ‡ä¹¦æ³•å’Œæ–‡ç« çš„è¯„ä»·ï¼›èº«è¨€åˆ™æ˜¯å¯¹å€™é€‰äººçš„å¤–è¡¨å’Œè¨€è¯­è¿›è¡Œè¯„ä¼°ï¼Œè¦æ±‚å…¶ä½“æ€ä¸°ä¼Ÿï¼Œè¨€è¾æ­£ç¡®ã€‚å¦‚æœå››è€…éƒ½åˆæ ¼ï¼Œæ‰èƒ½é€šè¿‡æ³¨å†Œã€æ¨ä¸¾ç­‰ç¨‹åºï¼Œæœ€ç»ˆç”±åéƒ¨ä¸ŠæŠ¥ç»™å°šä¹¦ä»†å°„ï¼Œå†ç»é—¨ä¸‹çœåå¤å®¡æ ¸ã€‚']\n"
     ]
    }
   ],
   "source": [
    "# question = \"Based on the documents, please reply to me in Chinese. What is the meaning of ä¸ƒä½?\"\n",
    "question = \"Based on the documents, are the author named é™³é¼ of æ»‡é»”åœŸå¸ã›°ç¦®è¨˜ and the author of æ»‡é»”ç´€æ¸¸ the same person? Please provide your reasons.\"\n",
    "results = rag_pipeline.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results[\"llm\"][\"replies\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
